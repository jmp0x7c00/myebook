import HTMLFlipBook from "react-pageflip";
import React, { useState, useRef, useEffect } from "react";
import "./App.css";

// ğŸ”¹ å…¨å±€æ¨¡å‹ç¼“å­˜ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼‰
let globalModel = null;
let voskModule = null;

function MyAlbum() {
  const bookRef = useRef();
  const [currentPage, setCurrentPage] = useState(0);
  const [isListening, setIsListening] = useState(false);
  const [pages, setPages] = useState([
    { text: "ç¬¬ä¸€é¡µå†…å®¹", image: null },
    { text: "ç¬¬äºŒé¡µå†…å®¹", image: null },
    { text: "ç¬¬ä¸‰é¡µå†…å®¹", image: null },
    { text: "ç¬¬å››é¡µå†…å®¹", image: null },
  ]);

  const audioCtxRef = useRef(null);
  const micStreamRef = useRef(null);
  const recognizerRef = useRef(null);

  // âœ… ä»…åˆå§‹åŒ–ä¸€æ¬¡æ¨¡å‹
  useEffect(() => {
    const initModel = async () => {
      if (!window.loadVosklet) return console.warn("Vosklet æœªåŠ è½½");

      voskModule = await window.loadVosklet();
      if (!globalModel) {
        console.log("ğŸ”¹ åŠ è½½æ¨¡å‹ä¸­...");
        globalModel = await voskModule.createModel(
          "https://ccoreilly.github.io/vosk-browser/models/vosk-model-small-en-us-0.15.tar.gz",
          "English",
          "vosk-model-small-en-us-0.15"
        );
        console.log("âœ… æ¨¡å‹åŠ è½½å®Œæˆ");
      }
    };
    initModel();

    // ğŸ”¹ é¡µé¢å¸è½½æ—¶é‡Šæ”¾æ¨¡å‹
    return () => {
      if (globalModel) {
        console.log("ğŸ§¹ é‡Šæ”¾æ¨¡å‹å†…å­˜");
        globalModel.terminate();
        globalModel = null;
      }
    };
  }, []);

  const handleFlip = (e) => setCurrentPage(e.data);

  // âœ… åœæ­¢å½•éŸ³ï¼ˆå®‰å…¨é‡Šæ”¾æ‰€æœ‰å†…å­˜ï¼‰
  const stopRecording = async () => {
    try {
      recognizerRef.current?.terminate?.();
      audioCtxRef.current?.close?.();
      micStreamRef.current?.getTracks()?.forEach((t) => t.stop());

      recognizerRef.current = null;
      micStreamRef.current = null;
      audioCtxRef.current = null;
      setIsListening(false);

      console.log("ğŸŸ¥ å½•éŸ³å·²åœæ­¢å¹¶é‡Šæ”¾èµ„æº");
    } catch (err) {
      console.error("åœæ­¢å½•éŸ³å¤±è´¥:", err);
    }
  };

  // âœ… å¯åŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆåªå¤ç”¨ä¸€ä¸ªæ¨¡å‹ï¼‰
  const startSpeechRecognition = async () => {
    if (!globalModel || !voskModule) {
      alert("æ¨¡å‹æœªå‡†å¤‡å¥½ï¼Œè¯·ç¨å€™å†è¯•");
      return;
    }

    if (isListening) return;
    setIsListening(true);

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const ctx = new AudioContext();
      const micNode = ctx.createMediaStreamSource(stream);
      audioCtxRef.current = ctx;
      micStreamRef.current = stream;

      const recognizer = new globalModel.KaldiRecognizer(ctx.sampleRate);
      recognizer.setWords(true);
      recognizerRef.current = recognizer;

      recognizer.on("result", (msg) => {
        const text = msg.result?.text || "";
        if (text) {
          const newPages = [...pages];
          newPages[currentPage - 1].text = text;
          setPages(newPages);
        }
        console.log("ğŸŸ¢ è¯†åˆ«ç»“æœï¼š", text);
      });

      recognizer.on("partialresult", (msg) => {
        console.log("ğŸŸ¡ Partial:", msg.result?.partial);
      });

      const transferer = await voskModule.createTransferer(ctx, 128 * 150);
      transferer.port.onmessage = (ev) => recognizer.acceptWaveform(ev.data);
      micNode.connect(transferer);

      // è‡ªåŠ¨åœæ­¢å½•éŸ³ï¼ˆ2åˆ†é’Ÿï¼‰
      setTimeout(stopRecording, 120000);
    } catch (err) {
      console.error("Vosklet Error:", err);
      alert("è¯­éŸ³è¯†åˆ«åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æƒé™ã€‚");
      setIsListening(false);
    }
  };

  const uploadImage = (e) => {
    const file = e.target.files[0];
    if (!file) return;
    const reader = new FileReader();
    reader.onload = (ev) => {
      const newPages = [...pages];
      newPages[currentPage - 1].image = ev.target.result;
      setPages(newPages);
    };
    reader.readAsDataURL(file);
  };

  return (
    <div style={{ backgroundColor: "LightCyan", minHeight: "100vh" }}>
      <HTMLFlipBook
        width={550}
        height={650}
        showCover
        flippingTime={1000}
        onFlip={handleFlip}
        ref={bookRef}
        style={{ margin: "0 auto" }}
      >
        <div className="cover">
          <h2>My EBook</h2>
        </div>
        {pages.map((p, i) => (
          <div key={i} className="page">
            <h2>ç¬¬ {i + 1} é¡µ</h2>
            <p>{p.text}</p>
            {p.image && <img src={p.image} alt="page" />}
          </div>
        ))}
        <div className="cover"></div>
      </HTMLFlipBook>

      <div style={{ textAlign: "center", marginTop: "20px" }}>
        <button
          onClick={isListening ? stopRecording : startSpeechRecognition}
          style={{
            backgroundColor: isListening ? "red" : "lightgreen",
            color: "white",
          }}
        >
          {isListening ? "åœæ­¢å½•éŸ³" : "ğŸ™ï¸ å¼€å§‹å½•éŸ³"}
        </button>
        <br />
        <input type="file" accept="image/*" onChange={uploadImage} />
      </div>
    </div>
  );
}

export default MyAlbum;
