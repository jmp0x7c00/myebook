/* global Vosk */
import HTMLFlipBook from "react-pageflip";
import React, { useState, useRef } from "react";
import bg from './bg.jpg';
import "./App.css";



// const PageCover = React.forwardRef((props, ref) => {
// 	return (
// 		<div
// 		className="cover"
// 		ref={ref}
// 		data-density="hard"
// 		style={{
// 			// backgroundImage: "url('/179175e8b0f611660ec7f67422b3ce71.jpeg')",
// 			// backgroundSize: "cover",
// 			// backgroundPosition: "center",
// 			// backgroundRepeat: "no-repeat"
// 		}}
// 		>
// 		<div>
// 		<h2>{props.children}</h2>
// 		</div>
// 		</div>
// 	);
// });

const PageCover = React.forwardRef(({ title, image, text }, ref) => {
  return (
    <div
      className="cover"
      ref={ref}
      data-density="hard"
      style={{
        // backgroundImage: `url(${bg})`,
        // backgroundSize: "cover",
        // backgroundPosition: "center",
        // position: "relative",
      }}
    >


	<h2 style={{ textAlign: "center" }}>{title}</h2>
								   
      {image && (
        <img
          src={image}
          alt="cover"
          style={{
            maxWidth: "100%",
            maxHeight: "100%",
            objectFit: "contain",
            display: "block",
            margin: "0 auto",
          }}
        />
      )}
      
      {text && (
        <p
          style={{
            whiteSpace: "pre-wrap",
            textAlign: "center",
            padding: "10px",
          }}
        >
          {text}
        </p>
      )}
    </div>
  );
});


const Page = React.forwardRef(({ number, content, image }, ref) => {
	return (
		<div className="page" ref={ref}>
		<h2>ç¬¬ {number} é¡µ</h2>
		<hr />
		{image && (
			<img
			src={image}
			alt="page"
			style={{ maxWidth: "100%", maxHeight: "300px", marginBottom: "10px" }}
			/>
		)}
		<p className="cartoon-text" style={{ whiteSpace: "pre-wrap" }}>{content}</p>
		</div>
	);
});


function floatTo16BitPCM(float32Array) {
    const buffer = new Int16Array(float32Array.length);
    for (let i = 0; i < float32Array.length; i++) {
        let s = Math.max(-1, Math.min(1, float32Array[i]));
        buffer[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
    }
    return buffer;
}

function MyAlbum() {
	const bookRef = useRef();
	const [currentPage, setCurrentPage] = useState(0);
	const [isListeningLeft, setIsListeningLeft] = useState(false);
	const [isListeningRight, setIsListeningRight] = useState(false);
	const [isModelLoading, setIsModelLoading] = useState(false);
	const modelRef = useRef(null);  // ğŸ”¹ ä¿å­˜å…¨å±€æ¨¡å‹
	
	// const [pages, setPages] = useState([
	// 	{ text: "ç¬¬ä¸€é¡µå†…å®¹", image: null },
	// 	{ text: "ç¬¬äºŒé¡µå†…å®¹", image: null },
	// 	{ text: "ç¬¬ä¸‰é¡µå†…å®¹", image: null },
	// 	{ text: "ç¬¬å››é¡µå†…å®¹", image: null },
	// ]);

	const [pages, setPages] = useState([
	  { text: "å°é¢å†…å®¹", image: null, isCover: true },
	  { text: "ç¬¬ä¸€é¡µå†…å®¹", image: null },
	  { text: "ç¬¬äºŒé¡µå†…å®¹", image: null },
	  { text: "ç¬¬ä¸‰é¡µå†…å®¹", image: null },
	]);

	// ç”¨äºä¿å­˜å½“å‰å½•éŸ³çš„ä¸Šä¸‹æ–‡
	const audioCtxRef = useRef(null);
	const micStreamRef = useRef(null);
	const recognizerRef = useRef(null);

	const handleFlip = (e) => {
		setCurrentPage(e.data);
	};

	// âœ… åœæ­¢å½•éŸ³
	const stopRecording = (side) => {
		try {
			if (audioCtxRef.current) {
				audioCtxRef.current.close();
				audioCtxRef.current = null;
			}
			if (micStreamRef.current) {
				micStreamRef.current.getTracks().forEach((track) => track.stop());
				micStreamRef.current = null;
			}
			if (recognizerRef.current) {
				recognizerRef.current.removeEventListener("result", () => {});
				recognizerRef.current = null;
			}

			if (side === "left") setIsListeningLeft(false);
			else setIsListeningRight(false);

			console.log("ğŸŸ¥ å½•éŸ³å·²åœæ­¢");
		} catch (err) {
			console.error("åœæ­¢å½•éŸ³å¤±è´¥:", err);
		}
	};

	// âœ… å¯åŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆVoskletï¼‰
	const startSpeechRecognition = async (side) => {
		try {

			// å¦‚æœæ¨¡å‹æ­£åœ¨åŠ è½½
			if (isModelLoading) {
				alert("æ¨¡å‹åŠ è½½ä¸­ï¼Œè¯·ç¨å...");
				return;
			}
		
		    if ((side === "left" && isListeningLeft) || (side === "right" && isListeningRight)) return;
		
		    if (!modelRef.current) {
	            setIsModelLoading(true);
	            modelRef.current = await Vosk.createModel(
	                "https://myebook-1257475696.cos.ap-shanghai.myqcloud.com/vosk-model-small-en-us-0.15.zip"
	            );
	            setIsModelLoading(false);
	            console.log("âœ… æ¨¡å‹åŠ è½½å®Œæˆ");
        	}
			const recognizer = new modelRef.current.KaldiRecognizer(48000);
			recognizer.setWords(true);
		    recognizer.on("result", (message) => {
		        console.log(`Result: ${message.result.text}`);
				const newPages = [...pages];
				let textOld = '';
				if (newPages[currentPage] && newPages[currentPage] .text){
					textOld = newPages[currentPage].text;
					if (!textOld || textOld === "" || textOld.includes('å†…å®¹')){
						textOld = '';
					} 
				}
		
				let raw = message.result.text.trim();
				if (raw.length > 0) {
				  raw = raw.charAt(0).toUpperCase() + raw.slice(1);
				}
				let textNew = `${raw}. `;
				
				if (textNew !== '. '){
					if (textOld.endsWith(textNew)){
						console.log(`é‡å¤å†…å®¹ï¼š ${textNew}, è¿‡æ»¤æ‰`);
						return;
					}
					textNew = textOld + textNew;
					newPages[currentPage].text = textNew;
					setPages(newPages);
				}
		    });
		    recognizer.on("partialresult", (message) => {
		        console.log(`Partial result: ${message.result.partial}`);
				
		    });				

			 const mediaStream = await navigator.mediaDevices.getUserMedia({
		        video: false,
		        audio: {
		            echoCancellation: true,
		            noiseSuppression: true,
		            channelCount: 1,
		            sampleRate: 16000
		        },
		    });
		    
		    const audioContext = new AudioContext();

			 await audioContext.resume();
			
		    
	        const source = audioContext.createMediaStreamSource(mediaStream);
	        const processor = audioContext.createScriptProcessor(4096, 1, 1);
	
	        processor.onaudioprocess = (event) => {
	            const audioBuffer = event.inputBuffer; // âœ… ä¿ç•™ AudioBuffer
    			recognizer.acceptWaveform(audioBuffer); // Vosk æ­£ç¡®ç±»å‹
	        };
	
	        source.connect(processor);
	        processor.connect(audioContext.destination);


			// âœ… ä¿å­˜ä¸Šä¸‹æ–‡
	        audioCtxRef.current = audioContext;
	        micStreamRef.current = mediaStream;
	        recognizerRef.current = recognizer;
	
	        // âœ… æ›´æ–°æŒ‰é’®çŠ¶æ€
	        if (side === "left") setIsListeningLeft(true);
	        else setIsListeningRight(true);
	
	        console.log("ğŸŸ© å½•éŸ³å·²å¼€å§‹");
					
		} catch (err) {
			alert(err);
			console.error("Vosklet Error:", err);
			alert("è¯­éŸ³è¯†åˆ«åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„æˆ–éº¦å…‹é£æƒé™ã€‚");
		}
	};

	// âœ… ä¸Šä¼ å›¾ç‰‡å‡½æ•°
	const uploadImage = (side, e) => {
		const file = e.target.files[0];
		if (!file) return;
		const reader = new FileReader();
		reader.onload = (event) => {
			const newPages = [...pages];
			newPages[currentPage].image = event.target.result;
			setPages(newPages);
		};
		reader.readAsDataURL(file);
	};

	return (
		<div
		  style={{
		    backgroundColor: "LightCyan",
		    overflow: "hidden",
		  }}
		>


		<div>
		<HTMLFlipBook
		width={550}
		height={650}
		minWidth={315}
		maxWidth={1000}
		minHeight={420}
		maxHeight={1350}
		showCover={true}
		flippingTime={1000}
		style={{ margin: "0 auto" }}
		maxShadowOpacity={0.5}
		className="album-web"
		ref={bookRef}
		onFlip={handleFlip}
		>

		{pages.map((p, i) =>
		    p.isCover ? (
		      <PageCover
		        key={i}
		        title="I am special!"
		        image={p.image}
		        text={p.text}
		      />
		    ) : (
		      <Page key={i} number={i} content={p.text} image={p.image} />
		    )
  		)}
		</HTMLFlipBook>

		<br />

		{/* âœ… å·¦å³è¯­éŸ³è¾“å…¥åŒº + æ–‡ä»¶ä¸Šä¼ åŒº + åˆ é™¤æŒ‰é’® */}
		{currentPage >= 0 && (
		<div className="formContainer" style={{ display: "flex", justifyContent: "center", alignItems: "center", gap: "20px", marginTop: "20px" }}>
		    {/* ä¸Šä¼ æŒ‰é’® */}
		    <button className="btn" style={{ backgroundColor: "#3498db", color: "white", border: "none", padding: "8px 16px", borderRadius: "6px", cursor: "pointer" }} onClick={() => document.getElementById("fileInputLeft").click()}>
		        ä¸Šä¼ å›¾ç‰‡
		    </button>
		    <input id="fileInputLeft" type="file" accept="image/*" style={{ display: "none" }} onChange={(e) => uploadImage("left", e)} />
		
		    {/* å½•éŸ³æŒ‰é’® */}
		    <button className="btn" onClick={() => isListeningLeft ? stopRecording("left") : startSpeechRecognition("left")} style={{
		        backgroundColor: isListeningLeft ? "red" : "lightgreen",
		        color: "white",
		        border: "none",
		        padding: "8px 16px",
		        borderRadius: "6px",
		        cursor: "pointer",
		    }}>
		        {isListeningLeft ? "åœæ­¢å½•éŸ³" : "ğŸ™ï¸ å¼€å§‹å½•éŸ³"}
		    </button>
		
		    {/* ğŸ”¹ åˆ é™¤æŒ‰é’® */}
		    <button className="btn" style={{
		        backgroundColor: "#e74c3c",
		        color: "white",
		        border: "none",
		        padding: "8px 16px",
		        borderRadius: "6px",
		        cursor: "pointer",
		    }} onClick={() => {
		        const newPages = [...pages];
		        const pageIndex = currentPage; // æ³¨æ„ PageCover å ä½
		        if (newPages[pageIndex] && newPages[pageIndex].text) {
		            let sentences = newPages[pageIndex].text.split(".").filter(s => s.trim() !== "");
		            if (sentences.length > 0) {
		                sentences.pop(); // åˆ é™¤æœ€åä¸€å¥
		                newPages[pageIndex].text = sentences.join(". ") + (sentences.length ? "." : "");
		                setPages(newPages);
		            }
		        }
		    }}>
		        åˆ é™¤æœ€åä¸€å¥
		    </button>
		</div>
		)}


		{/* <p style={{ textAlign: "center" }}>å½“å‰é¡µï¼šç¬¬ {currentPage + 1} é¡µ</p> */}
		</div>
		</div>
	);
}

export default MyAlbum;
