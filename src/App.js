/* global Vosk */
import HTMLFlipBook from "react-pageflip";
import React, { useState, useRef } from "react";
import bg from './bg.jpg';
import "./App.css";



const PageCover = React.forwardRef((props, ref) => {
	return (
		<div
		className="cover"
		ref={ref}
		data-density="hard"
		style={{
			// backgroundImage: "url('/bg.jpg')",
			// backgroundSize: "cover",
			// backgroundPosition: "center",
			// backgroundRepeat: "no-repeat"
		}}
		>
		<div>
		<h2>{props.children}</h2>
		</div>
		</div>
	);
});

const Page = React.forwardRef(({ number, content, image }, ref) => {
	return (
		<div className="page" ref={ref}>
		<h2>ç¬¬ {number} é¡µ</h2>
		<hr />
		{image && (
			<img
			src={image}
			alt="page"
			style={{ maxWidth: "100%", maxHeight: "300px", marginBottom: "10px" }}
			/>
		)}
		<p className="cartoon-text">{content}</p>
		</div>
	);
});

function MyAlbum() {
	const bookRef = useRef();
	const [currentPage, setCurrentPage] = useState(0);
	const [isListeningLeft, setIsListeningLeft] = useState(false);
	const [isListeningRight, setIsListeningRight] = useState(false);
	const [pages, setPages] = useState([
		{ text: "ç¬¬ä¸€é¡µå†…å®¹", image: null },
		{ text: "ç¬¬äºŒé¡µå†…å®¹", image: null },
		{ text: "ç¬¬ä¸‰é¡µå†…å®¹", image: null },
		{ text: "ç¬¬å››é¡µå†…å®¹", image: null },
	]);

	// ç”¨äºä¿å­˜å½“å‰å½•éŸ³çš„ä¸Šä¸‹æ–‡
	const audioCtxRef = useRef(null);
	const micStreamRef = useRef(null);
	const recognizerRef = useRef(null);

	const handleFlip = (e) => {
		setCurrentPage(e.data);
	};

	// âœ… åœæ­¢å½•éŸ³
	const stopRecording = (side) => {
		try {
			if (audioCtxRef.current) {
				audioCtxRef.current.close();
				audioCtxRef.current = null;
			}
			if (micStreamRef.current) {
				micStreamRef.current.getTracks().forEach((track) => track.stop());
				micStreamRef.current = null;
			}
			if (recognizerRef.current) {
				recognizerRef.current.removeEventListener("result", () => {});
				recognizerRef.current = null;
			}

			if (side === "left") setIsListeningLeft(false);
			else setIsListeningRight(false);

			console.log("ğŸŸ¥ å½•éŸ³å·²åœæ­¢");
		} catch (err) {
			console.error("åœæ­¢å½•éŸ³å¤±è´¥:", err);
		}
	};

	// âœ… å¯åŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆVoskletï¼‰
	const startSpeechRecognition = async (side) => {
		try {

			// ğŸ”¹ æœ€å°æ”¹åŠ¨ï¼šåªåœ¨æµè§ˆå™¨ç¯å¢ƒæ‰§è¡Œ
			if (typeof window === "undefined" || !navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
				console.warn("ğŸŸ¡ getUserMedia not available in this environment (probably server-side).");
				return;
			}
			if ((side === "left" && isListeningLeft) || (side === "right" && isListeningRight))
				return;

			// 1ï¸âƒ£ è·å–éº¦å…‹é£éŸ³é¢‘æµ
			// const stream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
			// const ctx = new AudioContext({ sinkId: { type: "none" } });
			// const micNode = ctx.createMediaStreamSource(stream);

			// audioCtxRef.current = ctx;
			// micStreamRef.current = stream;

			// 2ï¸âƒ£ åŠ è½½ Vosklet æ¨¡å—å’Œæ¨¡å‹
			//const module = await window.loadVosklet();
			//let model = await module.createModel(
			//	"https://myebook.asia:8000/vosk-model-small-en-us-0.15.tar.gz",
			//	"English",
			//	"vosk-model-small-en-us-0.15"
			//);
			//let model = await module.createModel("https://ccoreilly.github.io/vosk-browser/models/vosk-model-small-en-us-0.15.tar.gz","English","vosk-model-small-en-us-0.15");

			const model = await Vosk.createModel("https://ccoreilly.github.io/vosk-browser/models/vosk-model-small-en-us-0.15.tar.gz");
			const recognizer = new model.KaldiRecognizer(48000);
			recognizer.setWords(true);
		    recognizer.on("result", (message) => {
		        console.log(`Result: ${message.result.text}`);
		    });
		    recognizer.on("partialresult", (message) => {
		        console.log(`Partial result: ${message.result.partial}`);
		    });				

			 const mediaStream = await navigator.mediaDevices.getUserMedia({
		        video: false,
		        audio: {
		            echoCancellation: true,
		            noiseSuppression: true,
		            channelCount: 1,
		            sampleRate: 16000
		        },
		    });
		    
		    const audioContext = new AudioContext();
		    const recognizerNode = audioContext.createScriptProcessor(4096, 1, 1)
		    recognizerNode.onaudioprocess = (event) => {
		        try {
		            recognizer.acceptWaveform(event.inputBuffer)
		        } catch (error) {
		            console.error('acceptWaveform failed', error)
		        }
		    }
		    const source = audioContext.createMediaStreamSource(mediaStream);
		    source.connect(recognizerNode);
					
			
			// const recognizer = await module.createRecognizer(model, ctx.sampleRate);
			// recognizerRef.current = recognizer;

			// 3ï¸âƒ£ è¯†åˆ«ç»“æœäº‹ä»¶
			// recognizer.addEventListener("result", (ev) => {
			// 	const transcript = ev.detail?.text || ev.detail;
			// 	// alert("è¯†åˆ«ç»“æœ: " + transcript);
			// 	console.log(transcript);

			// 	const newPages = [...pages];
			// 	const transcriptObj = JSON.parse(transcript)
			// 	if (transcriptObj && transcriptObj["text"]){
			// 		newPages[currentPage - 1].text = transcriptObj["text"];
			// 		setPages(newPages);
			// 	}

			// 	// const targetPage =
			// 	//   side === "left"
			// 	//     ? currentPage % 2 === 0
			// 	//       ? currentPage
			// 	//       : currentPage - 1
			// 	//     : currentPage % 2 === 0
			// 	//     ? currentPage + 1
			// 	//     : currentPage;

			// 	// if (targetPage >= 0 && targetPage < newPages.length) {
			// 	//   const transcriptObj = JSON.parse(transcript)
			// 	//   if (transcriptObj && transcriptObj["text"]){
			// 	//       newPages[targetPage].text = transcriptObj["text"];
			// 	//       setPages(newPages);
			// 	//   }
			// 	// }
			// });

			// recognizer.addEventListener("partialResult", (ev) => {
			// 	console.log("ğŸŸ¡ Partial:", ev.detail);
			// });

			// // 4ï¸âƒ£ åˆ›å»ºä¼ è¾“èŠ‚ç‚¹
			// //const transferer = await module.createTransferer(ctx, 128 * 150);
			// const transferer = await module.createTransferer(ctx, 128 * 150, { useSharedArrayBuffer: true });
			// transferer.port.onmessage = (ev) => recognizer.acceptWaveform(ev.data);

			// // 5ï¸âƒ£ è¿æ¥éº¦å…‹é£
			// micNode.connect(transferer);

			// // 6ï¸âƒ£ çŠ¶æ€æ§åˆ¶
			// if (side === "left") setIsListeningLeft(true);
			// else setIsListeningRight(true);

			// // 7ï¸âƒ£ è‡ªåŠ¨åœæ­¢å½•éŸ³ï¼ˆ3åˆ†é’Ÿï¼‰
			// setTimeout(() => stopRecording(side), 180000);
		} catch (err) {
			alert(err);
			console.error("Vosklet Error:", err);
			alert("è¯­éŸ³è¯†åˆ«åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„æˆ–éº¦å…‹é£æƒé™ã€‚");
		}
	};

	// âœ… ä¸Šä¼ å›¾ç‰‡å‡½æ•°
	const uploadImage = (side, e) => {
		const file = e.target.files[0];
		if (!file) return;
		const reader = new FileReader();
		reader.onload = (event) => {
			const newPages = [...pages];
			newPages[currentPage - 1].image = event.target.result;
			setPages(newPages);
		};
		reader.readAsDataURL(file);
	};

	return (
		<div style={{ backgroundColor: "LightCyan", minHeight: "100vh" }}>


		<div>
		<HTMLFlipBook
		width={550}
		height={650}
		minWidth={315}
		maxWidth={1000}
		minHeight={420}
		maxHeight={1350}
		showCover={true}
		flippingTime={1000}
		style={{ margin: "0 auto" }}
		maxShadowOpacity={0.5}
		className="album-web"
		ref={bookRef}
		onFlip={handleFlip}
		>
		<PageCover>My EBook</PageCover>
		{pages.map((p, i) => (
			<Page key={i} number={i + 1} content={p.text} image={p.image} />
		))}
		<PageCover></PageCover>
		</HTMLFlipBook>

		<br />

		{/* âœ… å·¦å³è¯­éŸ³è¾“å…¥åŒº + æ–‡ä»¶ä¸Šä¼ åŒº */}
		<div
		className="formContainer"
		style={{
			display: "flex",
				justifyContent: "center",
				alignItems: "flex-start",
				gap: "40px",
				marginTop: "20px",
		}}
		>
		{/* å·¦é¡µè¯­éŸ³ */}
		<div style={{ textAlign: "center" }}>
		<button
		className="btn"
		onClick={() =>
			isListeningLeft ? stopRecording("left") : startSpeechRecognition("left")
		}
		style={{
			backgroundColor: isListeningLeft ? "red" : "lightgreen",
				color: "white",
		}}
		>
		{isListeningLeft ? "åœæ­¢å½•éŸ³" : "ğŸ™ï¸ å¼€å§‹å½•éŸ³"}
		</button>
		<br />
		<input type="file" accept="image/*" onChange={(e) => uploadImage("left", e)} />
		</div>
		</div>

		{/* <p style={{ textAlign: "center" }}>å½“å‰é¡µï¼šç¬¬ {currentPage + 1} é¡µ</p> */}
		</div>
		</div>
	);
}

export default MyAlbum;
